---
contactPerson: /person/o.rubi
engineer:
- /person/o.rubi
endorsedBy:
- /organization/nlesc
involvedOrganization:
- /organization/utwente
- /organization/ign
- /organization/nlesc
logo: /images/project/improving-photogrammetry.jpg
name: Improving Open-Source Photogrammetric Workflows for Processing Big Datasets
tagLine: Improving Open-Source Photogrammetric Workflows for Processing Big Datasets
uses:
- /software/micmac
- /software/noodles
- /software/pycoeman
- /software/pymicmac
---
Aerial imagery over urban areas is increasingly being used to provide detailed imagery and 3D models to support many applications such as map updating, urban planning and water management. The size of such photogrammetric projects is increasing rapidly, causing a scramble for hardware with more memory and processing power. A conventional UAV (Unmanned Aerial Vehicle) flight can collect thousands of images and conventional photogrammetric sensors can acquire images of more than 200 Megapixels in size.

Nowadays, the need of high performance hardware represents one of the main bottlenecks in the development of efficient automated applications exploiting photogrammetry over large areas. This Path-Finding Project will implement three tools for processing of large datasets able to run on consumer-grade computers.

Two case studies are used to test the developed tools. The first considers how to make photogrammetric workflows accessible to end-users lacking advanced hardware, such as city planners in developing countries. In 2015, 16.000 images covering 150 hectare were collected over informal settlements in Kigali, Rwanda using a low-cost UAV. To analyze the potential of UAVs to provide accurate geo-information to support informal settlement upgrading projects, the workflow should be completed using consumer-grade computers.

The second case study is related to mapping applications. Recently, projects have been developed to update national 3D models, for example the Dutch digital height model (AHN), through DIM from aerial images. The goal is to automatically process this enormous block using a consumer-grade PC. The dataset over Rotterdam will be used for this task.
